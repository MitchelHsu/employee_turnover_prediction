{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../p_train.csv')\n",
    "st = pd.read_csv('../PerStatus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.780673</td>\n",
       "      <td>4.253273</td>\n",
       "      <td>3.581893</td>\n",
       "      <td>0.464752</td>\n",
       "      <td>-1.257239</td>\n",
       "      <td>2.005170</td>\n",
       "      <td>0.894422</td>\n",
       "      <td>-2.945006</td>\n",
       "      <td>-2.605545</td>\n",
       "      <td>-1.516003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.222298</td>\n",
       "      <td>5.180612</td>\n",
       "      <td>3.095280</td>\n",
       "      <td>0.544007</td>\n",
       "      <td>0.672532</td>\n",
       "      <td>-1.044113</td>\n",
       "      <td>1.210943</td>\n",
       "      <td>-1.989780</td>\n",
       "      <td>-2.708660</td>\n",
       "      <td>-2.084618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.097701</td>\n",
       "      <td>3.492900</td>\n",
       "      <td>2.712022</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>0.967701</td>\n",
       "      <td>-1.399888</td>\n",
       "      <td>1.878681</td>\n",
       "      <td>-1.496398</td>\n",
       "      <td>-2.255684</td>\n",
       "      <td>-2.664238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.097420</td>\n",
       "      <td>4.150639</td>\n",
       "      <td>2.637380</td>\n",
       "      <td>-0.201422</td>\n",
       "      <td>0.907423</td>\n",
       "      <td>-2.188522</td>\n",
       "      <td>2.457380</td>\n",
       "      <td>-1.579802</td>\n",
       "      <td>-2.565915</td>\n",
       "      <td>-3.126221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063414</td>\n",
       "      <td>-1.339554</td>\n",
       "      <td>-2.547600</td>\n",
       "      <td>-0.630693</td>\n",
       "      <td>0.820306</td>\n",
       "      <td>-1.022422</td>\n",
       "      <td>0.162423</td>\n",
       "      <td>-0.039809</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>-0.185158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14387</th>\n",
       "      <td>2.781541</td>\n",
       "      <td>-1.263983</td>\n",
       "      <td>-1.414272</td>\n",
       "      <td>-0.386429</td>\n",
       "      <td>0.147587</td>\n",
       "      <td>-1.237856</td>\n",
       "      <td>0.374852</td>\n",
       "      <td>0.584224</td>\n",
       "      <td>0.283463</td>\n",
       "      <td>0.810674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14388</th>\n",
       "      <td>2.795151</td>\n",
       "      <td>-1.517755</td>\n",
       "      <td>-1.187404</td>\n",
       "      <td>-0.116658</td>\n",
       "      <td>0.518678</td>\n",
       "      <td>-1.085898</td>\n",
       "      <td>0.193873</td>\n",
       "      <td>0.465489</td>\n",
       "      <td>0.504242</td>\n",
       "      <td>0.888705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14389</th>\n",
       "      <td>3.472010</td>\n",
       "      <td>-1.162631</td>\n",
       "      <td>-1.456444</td>\n",
       "      <td>-0.502278</td>\n",
       "      <td>0.275183</td>\n",
       "      <td>-1.087539</td>\n",
       "      <td>0.310765</td>\n",
       "      <td>0.564877</td>\n",
       "      <td>0.383407</td>\n",
       "      <td>0.968338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>3.578266</td>\n",
       "      <td>-1.035361</td>\n",
       "      <td>-1.388147</td>\n",
       "      <td>-0.172793</td>\n",
       "      <td>-0.272741</td>\n",
       "      <td>-0.276563</td>\n",
       "      <td>0.205929</td>\n",
       "      <td>0.367964</td>\n",
       "      <td>1.385141</td>\n",
       "      <td>1.166554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14391</th>\n",
       "      <td>2.884324</td>\n",
       "      <td>4.150729</td>\n",
       "      <td>4.056280</td>\n",
       "      <td>4.173290</td>\n",
       "      <td>-2.899063</td>\n",
       "      <td>2.504799</td>\n",
       "      <td>-0.855304</td>\n",
       "      <td>-2.177580</td>\n",
       "      <td>-0.104551</td>\n",
       "      <td>2.497862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14392 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pca1      pca2      pca3      pca4      pca5      pca6      pca7  \\\n",
       "0     -1.780673  4.253273  3.581893  0.464752 -1.257239  2.005170  0.894422   \n",
       "1     -1.222298  5.180612  3.095280  0.544007  0.672532 -1.044113  1.210943   \n",
       "2     -1.097701  3.492900  2.712022  0.076471  0.967701 -1.399888  1.878681   \n",
       "3     -1.097420  4.150639  2.637380 -0.201422  0.907423 -2.188522  2.457380   \n",
       "4      2.063414 -1.339554 -2.547600 -0.630693  0.820306 -1.022422  0.162423   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14387  2.781541 -1.263983 -1.414272 -0.386429  0.147587 -1.237856  0.374852   \n",
       "14388  2.795151 -1.517755 -1.187404 -0.116658  0.518678 -1.085898  0.193873   \n",
       "14389  3.472010 -1.162631 -1.456444 -0.502278  0.275183 -1.087539  0.310765   \n",
       "14390  3.578266 -1.035361 -1.388147 -0.172793 -0.272741 -0.276563  0.205929   \n",
       "14391  2.884324  4.150729  4.056280  4.173290 -2.899063  2.504799 -0.855304   \n",
       "\n",
       "           pca8      pca9     pca10  \n",
       "0     -2.945006 -2.605545 -1.516003  \n",
       "1     -1.989780 -2.708660 -2.084618  \n",
       "2     -1.496398 -2.255684 -2.664238  \n",
       "3     -1.579802 -2.565915 -3.126221  \n",
       "4     -0.039809  0.046711 -0.185158  \n",
       "...         ...       ...       ...  \n",
       "14387  0.584224  0.283463  0.810674  \n",
       "14388  0.465489  0.504242  0.888705  \n",
       "14389  0.564877  0.383407  0.968338  \n",
       "14390  0.367964  1.385141  1.166554  \n",
       "14391 -2.177580 -0.104551  2.497862  \n",
       "\n",
       "[14392 rows x 10 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_DF = pd.DataFrame(data=pca_data, columns=['pca' + str(x) for x in range(1, 11)])\n",
    "pca_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pca_DF.values\n",
    "Y = st.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, MultinomialNB\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, r2_score\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import dump\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8856309060589216\n",
      "RMSE: 0.34\n",
      "R_squared: -1.19\n",
      "Recall score: 0.1092964824120603\n",
      "Fbeta score: 0.10044404973357016\n"
     ]
    }
   ],
   "source": [
    "#Make pipeline of clf\n",
    "clf_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "y_pred = cross_val_predict(clf_pipeline, X, Y, cv=10)\n",
    "print('Accuracy score:', metrics.accuracy_score(Y, y_pred))\n",
    "print('RMSE:', round(sqrt(mean_squared_error(Y, y_pred)), 2))\n",
    "print('R_squared:', round(r2_score(Y, y_pred), 2))\n",
    "print('Recall score:', metrics.recall_score(Y, y_pred))\n",
    "print('Fbeta score:', fbeta_score(Y, y_pred, beta=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
