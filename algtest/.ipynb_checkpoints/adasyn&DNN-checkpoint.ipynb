{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import make_pipeline as imb_pipline\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, r2_score\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../p_train.csv')\n",
    "target = pd.read_csv('../PerStatus.csv')\n",
    "data.drop(['Work Overtime'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../E_data/stest.csv')\n",
    "test.drop(['Unnamed: 0', 'PerStatus', 'PerNo', 'Work Overtime'], axis=1, inplace=True)\n",
    "test.columns = data.columns\n",
    "test.ffill(inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = data.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "categorical_columns = full.columns\n",
    "categorical_pipeline = make_pipeline(\n",
    "    SimpleImputer(missing_values=-1, strategy='most_frequent'),\n",
    "    OneHotEncoder(categories='auto'))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [('categorical_preprocessing', categorical_pipeline, categorical_columns)],\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "def build_model(n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(n_features,),\n",
    "              kernel_initializer='glorot_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, kernel_initializer='glorot_normal', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', Recall(name='recall')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.keras import BalancedBatchGenerator\n",
    "\n",
    "def fit_predict_balanced_model(X_train, Y_train, X_test, Y_test):\n",
    "    model = build_model(X_train.shape[1])\n",
    "    training_generator = BalancedBatchGenerator(X_train, Y_train,\n",
    "                                                batch_size=100,\n",
    "                                                random_state=42)\n",
    "    model.fit_generator(generator=training_generator, epochs=50, verbose=1)\n",
    "    y_pred = model.predict_proba(X_test, batch_size=300)\n",
    "    return roc_auc_score(Y_test, y_pred), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.5045 - recall: 0.7705\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5536 - recall: 0.7814\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6027 - recall: 0.7796\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6209 - recall: 0.7541\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6827 - recall: 0.7851\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6791 - recall: 0.7286\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6955 - recall: 0.7577\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7073 - recall: 0.7450\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7427 - recall: 0.7760\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7345 - recall: 0.7650\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7482 - recall: 0.7760\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7727 - recall: 0.8087\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7745 - recall: 0.7668\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7918 - recall: 0.7960\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7964 - recall: 0.8197\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8209 - recall: 0.8197\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8155 - recall: 0.8233\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8227 - recall: 0.8251\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8018 - recall: 0.7960\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8445 - recall: 0.8434\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8436 - recall: 0.8434\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8645 - recall: 0.8452\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8709 - recall: 0.8543\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8518 - recall: 0.8434\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8855 - recall: 0.8834\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8836 - recall: 0.8725\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8909 - recall: 0.8944\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8836 - recall: 0.8689\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9091 - recall: 0.9016\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.9018 - recall: 0.9016\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2675 - accuracy: 0.9027 - recall: 0.8944\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9300 - recall: 0.9235\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9282 - recall: 0.9290\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.9109 - recall: 0.9053\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9327 - recall: 0.9199\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9327 - recall: 0.9253\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9400 - recall: 0.9381\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9418 - recall: 0.9326\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9391 - recall: 0.9344\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9518 - recall: 0.9381\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9600 - recall: 0.9563\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9555 - recall: 0.9563\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9645 - recall: 0.9690\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9545 - recall: 0.9381\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9636 - recall: 0.9472\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9618 - recall: 0.9727\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9682 - recall: 0.9617\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9600 - recall: 0.9490\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9636 - recall: 0.9545\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9727 - recall: 0.9672\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7951 - accuracy: 0.4882 - recall: 0.5519\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.6009 - recall: 0.6740\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6182 - recall: 0.6685\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6355 - recall: 0.6594\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6509 - recall: 0.6703\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6936 - recall: 0.7067\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7209 - recall: 0.7177\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7264 - recall: 0.7195\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7436 - recall: 0.7322\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7600 - recall: 0.7523\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7718 - recall: 0.7614\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7618 - recall: 0.7486\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7864 - recall: 0.7668\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7927 - recall: 0.7723\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8091 - recall: 0.7869\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8236 - recall: 0.8069\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8245 - recall: 0.8051\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8409 - recall: 0.8179\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8455 - recall: 0.8160\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8736 - recall: 0.8616\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8536 - recall: 0.8233\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8718 - recall: 0.8470\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8645 - recall: 0.8488\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8955 - recall: 0.8761\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8855 - recall: 0.8561\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8927 - recall: 0.8743\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8909 - recall: 0.8597\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.9045 - recall: 0.8907\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9091 - recall: 0.9107\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9136 - recall: 0.9071\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9100 - recall: 0.8852\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9118 - recall: 0.8980\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.9318 - recall: 0.9162\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9473 - recall: 0.9271\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9445 - recall: 0.9326\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9482 - recall: 0.9417\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9455 - recall: 0.9362\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9600 - recall: 0.9526\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9536 - recall: 0.9526\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9500 - recall: 0.9454\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9609 - recall: 0.9472\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9582 - recall: 0.9563\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9636 - recall: 0.9599\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9664 - recall: 0.9545\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9645 - recall: 0.9672\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9718 - recall: 0.9690\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9627 - recall: 0.9526\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9736 - recall: 0.9709\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.9782 - recall: 0.9800\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9700 - recall: 0.9672\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7575 - accuracy: 0.5573 - recall: 0.6284\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5673 - recall: 0.6430\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6482 - recall: 0.6922\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6791 - recall: 0.7013\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6727 - recall: 0.6958\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7145 - recall: 0.7322\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7173 - recall: 0.7341\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7145 - recall: 0.7268\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7464 - recall: 0.7577\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7727 - recall: 0.7960\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7600 - recall: 0.7668\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7827 - recall: 0.7851\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7936 - recall: 0.8015\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8182 - recall: 0.8288\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8182 - recall: 0.8233\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8191 - recall: 0.8179\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8236 - recall: 0.8306\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8382 - recall: 0.8215\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8545 - recall: 0.8543\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8627 - recall: 0.8506\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8773 - recall: 0.8670\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8691 - recall: 0.8689\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8791 - recall: 0.8780\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8891 - recall: 0.8998\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8964 - recall: 0.8889\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8991 - recall: 0.8980\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.9036 - recall: 0.8944\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2721 - accuracy: 0.9055 - recall: 0.8998\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9191 - recall: 0.9126\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8982 - recall: 0.8944\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9245 - recall: 0.9290\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9191 - recall: 0.9235\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9327 - recall: 0.9326\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9345 - recall: 0.9217\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9418 - recall: 0.9417\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9518 - recall: 0.9526\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9291 - recall: 0.9199\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9364 - recall: 0.9235\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 0.9445 - recall: 0.9381\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9536 - recall: 0.9581\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9527 - recall: 0.9617\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1563 - accuracy: 0.9591 - recall: 0.9435\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9527 - recall: 0.9472\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9673 - recall: 0.9654\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9655 - recall: 0.9709\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9636 - recall: 0.9617\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9591 - recall: 0.9545\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9673 - recall: 0.9709\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9782 - recall: 0.9800\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9664 - recall: 0.9709\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7738 - accuracy: 0.5364 - recall: 0.6703\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.5882 - recall: 0.6995\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6509 - recall: 0.7195\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6845 - recall: 0.7450\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.6927 - recall: 0.7286\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7264 - recall: 0.7468\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7400 - recall: 0.7432\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7382 - recall: 0.7450\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7482 - recall: 0.7432\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7745 - recall: 0.7668\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7982 - recall: 0.7887\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7991 - recall: 0.7923\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7991 - recall: 0.7851\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8264 - recall: 0.8324\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8136 - recall: 0.7996\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8409 - recall: 0.8379\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8409 - recall: 0.8270\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8427 - recall: 0.8506\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8536 - recall: 0.8215\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8818 - recall: 0.8634\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8645 - recall: 0.8597\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8627 - recall: 0.8470\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8845 - recall: 0.8689\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.9036 - recall: 0.9107\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9082 - recall: 0.9016\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9064 - recall: 0.8889\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9209 - recall: 0.9035\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9127 - recall: 0.9071\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9118 - recall: 0.8980\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9227 - recall: 0.9199\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9345 - recall: 0.9235\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9482 - recall: 0.9472\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9291 - recall: 0.9217\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9436 - recall: 0.9381\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9464 - recall: 0.9472\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.9491 - recall: 0.9545\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9427 - recall: 0.9472\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9536 - recall: 0.9508\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9618 - recall: 0.9672\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9609 - recall: 0.9581\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9300 - recall: 0.895 - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9491 - recall: 0.9435\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9627 - recall: 0.9727\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9618 - recall: 0.9508\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9655 - recall: 0.9745\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9700 - recall: 0.9781\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9664 - recall: 0.9617\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9736 - recall: 0.9654\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9791 - recall: 0.9818\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9764 - recall: 0.9781\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9773 - recall: 0.9781\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7829 - accuracy: 0.4955 - recall: 0.1767\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7173 - accuracy: 0.5655 - recall: 0.2842\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6182 - recall: 0.3843\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6255 - recall: 0.4299\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6809 - recall: 0.5301\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6836 - recall: 0.5464\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7045 - recall: 0.5920\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7200 - recall: 0.6193\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7291 - recall: 0.6721\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7564 - recall: 0.7195\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7709 - recall: 0.7486\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7718 - recall: 0.7541\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7882 - recall: 0.7650\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7855 - recall: 0.7814\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7982 - recall: 0.7923\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8218 - recall: 0.8087\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8009 - recall: 0.7814\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8455 - recall: 0.8525\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8573 - recall: 0.8597\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8655 - recall: 0.8689\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8573 - recall: 0.8506\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8691 - recall: 0.8761\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8727 - recall: 0.8816\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8936 - recall: 0.8944\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8945 - recall: 0.8816\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.9009 - recall: 0.9016\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9136 - recall: 0.9217\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.9155 - recall: 0.9326\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2757 - accuracy: 0.9164 - recall: 0.9126\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.9200 - recall: 0.9253\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9236 - recall: 0.9326\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9400 - recall: 0.9435\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9400 - recall: 0.9472\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9491 - recall: 0.9526\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9455 - recall: 0.9435\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9482 - recall: 0.9490\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9518 - recall: 0.9508\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9582 - recall: 0.9545\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9664 - recall: 0.9709\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9518 - recall: 0.9581\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9600 - recall: 0.9563\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9645 - recall: 0.9672\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9764 - recall: 0.9800\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9827 - recall: 0.9763\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9700 - recall: 0.9727\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9700 - recall: 0.9763\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9691 - recall: 0.9672\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9727 - recall: 0.9709\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9773 - recall: 0.9800\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9764 - recall: 0.9800\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8052 - accuracy: 0.4918 - recall: 0.5829\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7055 - accuracy: 0.5809 - recall: 0.6193\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6227 - recall: 0.6776\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6718 - recall: 0.7250\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7055 - recall: 0.7432\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7036 - recall: 0.7177\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7045 - recall: 0.7286\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7364 - recall: 0.7614\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7827 - recall: 0.8160\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7427 - recall: 0.7668\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7518 - recall: 0.7650\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7873 - recall: 0.7942\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8009 - recall: 0.7978\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8055 - recall: 0.8160\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8155 - recall: 0.8033\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8291 - recall: 0.8160\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8173 - recall: 0.8069\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8455 - recall: 0.8434\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8427 - recall: 0.8506\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8627 - recall: 0.8634\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8627 - recall: 0.8506\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8700 - recall: 0.8743\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8873 - recall: 0.8725\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8936 - recall: 0.8944\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8764 - recall: 0.8707\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8973 - recall: 0.8980\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9173 - recall: 0.9089\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9191 - recall: 0.9089\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9027 - recall: 0.9071\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9191 - recall: 0.9089\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9300 - recall: 0.9253\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.9282 - recall: 0.9253\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9173 - recall: 0.9162\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9409 - recall: 0.9435\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9273 - recall: 0.9162\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9500 - recall: 0.9454\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9500 - recall: 0.9454\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9618 - recall: 0.9599\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9482 - recall: 0.9417\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9582 - recall: 0.9454\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9691 - recall: 0.9654\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9636 - recall: 0.9581\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9600 - recall: 0.9490\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9709 - recall: 0.9709\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9636 - recall: 0.9563\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9673 - recall: 0.9636\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9609 - recall: 0.9563\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9773 - recall: 0.9745\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9727 - recall: 0.9690\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9809 - recall: 0.9818\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8500 - accuracy: 0.5109 - recall: 0.8142\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.5845 - recall: 0.8634\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.6018 - recall: 0.8342\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.6418 - recall: 0.8288\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.6755 - recall: 0.8306\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7073 - recall: 0.8215\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7355 - recall: 0.8470\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7273 - recall: 0.8288\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7700 - recall: 0.8506\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7864 - recall: 0.8543\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7782 - recall: 0.8306\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8091 - recall: 0.8561\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7982 - recall: 0.8525\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8127 - recall: 0.8561\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8264 - recall: 0.8561\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8373 - recall: 0.8761\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8436 - recall: 0.8597\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8545 - recall: 0.8725\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8636 - recall: 0.8834\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8709 - recall: 0.8816\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8700 - recall: 0.8834\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8791 - recall: 0.8907\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8973 - recall: 0.9126\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.9055 - recall: 0.9162\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.9073 - recall: 0.9217\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9191 - recall: 0.9217\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.9000 - recall: 0.8889\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9318 - recall: 0.9344\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9218 - recall: 0.9344\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.9264 - recall: 0.9271\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2298 - accuracy: 0.9427 - recall: 0.9399\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9364 - recall: 0.9308\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9409 - recall: 0.9417\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9409 - recall: 0.9417\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9509 - recall: 0.9344\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9600 - recall: 0.9636\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9445 - recall: 0.9435\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9545 - recall: 0.9526\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9645 - recall: 0.9672\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9627 - recall: 0.9654\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9764 - recall: 0.9672\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9664 - recall: 0.9617\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9809 - recall: 0.9763\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9618 - recall: 0.9599\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9718 - recall: 0.9763\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9718 - recall: 0.9654\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9773 - recall: 0.9690\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9627 - recall: 0.9490\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9782 - recall: 0.9781\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9755 - recall: 0.9654\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.5391 - recall: 0.6521\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5882 - recall: 0.6721\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6064 - recall: 0.6740\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6700 - recall: 0.7140\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.7064 - recall: 0.7486\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7018 - recall: 0.7195\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7109 - recall: 0.7450\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7345 - recall: 0.7450\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7509 - recall: 0.7505\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7673 - recall: 0.7668\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7727 - recall: 0.7741\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7918 - recall: 0.8124\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7927 - recall: 0.7960\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8045 - recall: 0.8069\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8218 - recall: 0.8288\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8027 - recall: 0.8033\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8364 - recall: 0.8361\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8500 - recall: 0.8397\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8418 - recall: 0.8506\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8536 - recall: 0.8616\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8673 - recall: 0.8616\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8845 - recall: 0.8834\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8809 - recall: 0.8616\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8836 - recall: 0.8689\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8918 - recall: 0.8962\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8991 - recall: 0.8998\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9091 - recall: 0.9035\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9127 - recall: 0.8980\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.9209 - recall: 0.9162\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9127 - recall: 0.9144\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9209 - recall: 0.9126\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9373 - recall: 0.9399\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9345 - recall: 0.9271\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9318 - recall: 0.9344\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9482 - recall: 0.9417\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9409 - recall: 0.9417\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9545 - recall: 0.9472\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9391 - recall: 0.9399\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9445 - recall: 0.9381\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9518 - recall: 0.9454\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9600 - recall: 0.9599\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9664 - recall: 0.9526\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9582 - recall: 0.9545\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9700 - recall: 0.9709\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9573 - recall: 0.9508\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9700 - recall: 0.9727\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9691 - recall: 0.9636\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9736 - recall: 0.9727\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9773 - recall: 0.9763\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9655 - recall: 0.9636\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7429 - accuracy: 0.5409 - recall: 0.6029\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6200 - recall: 0.6521\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6364 - recall: 0.6430\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6427 - recall: 0.6266\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7009 - recall: 0.7213\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6982 - recall: 0.6885\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7355 - recall: 0.7359\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7409 - recall: 0.7432\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7455 - recall: 0.7413\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7736 - recall: 0.7432\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7664 - recall: 0.7468\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7882 - recall: 0.7851\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8064 - recall: 0.7960\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8136 - recall: 0.8069\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8191 - recall: 0.8179\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8345 - recall: 0.8197\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8255 - recall: 0.8106\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8409 - recall: 0.8051\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8509 - recall: 0.8270\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8564 - recall: 0.8452\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8627 - recall: 0.8488\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8782 - recall: 0.8543\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8891 - recall: 0.8689\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8982 - recall: 0.8834\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8909 - recall: 0.8634\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8764 - recall: 0.8579\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9082 - recall: 0.8871\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.9109 - recall: 0.8980\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9200 - recall: 0.9016\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.9255 - recall: 0.9162\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9382 - recall: 0.9344\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9236 - recall: 0.9162\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9264 - recall: 0.9071\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9355 - recall: 0.9217\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9418 - recall: 0.9362\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9382 - recall: 0.9217\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9436 - recall: 0.9290\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9418 - recall: 0.9308\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1732 - accuracy: 0.9500 - recall: 0.9490\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9536 - recall: 0.9435\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9591 - recall: 0.9526\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9555 - recall: 0.9563\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9700 - recall: 0.9599\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9609 - recall: 0.9581\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9691 - recall: 0.9690\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9636 - recall: 0.9636\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9618 - recall: 0.9599\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9700 - recall: 0.9636\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9736 - recall: 0.9781\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9755 - recall: 0.9672\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8037 - accuracy: 0.5364 - recall: 0.6539\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.5909 - recall: 0.6667\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.6436 - recall: 0.7158\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6809 - recall: 0.7322\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6936 - recall: 0.7596\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7045 - recall: 0.7541\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7227 - recall: 0.7413\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7427 - recall: 0.7705\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7618 - recall: 0.7741\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7582 - recall: 0.7523\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7864 - recall: 0.7942\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7964 - recall: 0.7796\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8064 - recall: 0.8106\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7818 - recall: 0.7778\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8218 - recall: 0.8270\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8373 - recall: 0.8470\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8464 - recall: 0.8452\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8318 - recall: 0.8233\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8491 - recall: 0.8434\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8482 - recall: 0.8525\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8545 - recall: 0.8525\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8809 - recall: 0.8707\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8655 - recall: 0.8579\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8818 - recall: 0.8743\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8864 - recall: 0.8889\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8973 - recall: 0.9107\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8864 - recall: 0.8798\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.8873 - recall: 0.8852\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8909 - recall: 0.8871\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9173 - recall: 0.9089\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9109 - recall: 0.9053\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9245 - recall: 0.9271\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.9136 - recall: 0.9199\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9236 - recall: 0.9107\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9355 - recall: 0.9362\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9418 - recall: 0.9381\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9373 - recall: 0.9399\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9382 - recall: 0.9399\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9336 - recall: 0.9235\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9545 - recall: 0.9472\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9482 - recall: 0.9508\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1569 - accuracy: 0.9518 - recall: 0.9454\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1557 - accuracy: 0.9518 - recall: 0.9417\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9555 - recall: 0.9526\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9518 - recall: 0.9508\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9645 - recall: 0.9617\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9618 - recall: 0.9526\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9709 - recall: 0.9654\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9555 - recall: 0.9508\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9618 - recall: 0.9636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "full = preprocessor.fit_transform(full)\n",
    "models = []\n",
    "\n",
    "cv_results_balanced = []\n",
    "for train_idx, valid_idx in skf.split(X_train, Y_train):\n",
    "    X_local_train = preprocessor.transform(X_train.iloc[train_idx])\n",
    "    y_local_train = Y_train.iloc[train_idx].values.ravel()\n",
    "    X_local_test = preprocessor.transform(X_train.iloc[valid_idx])\n",
    "    y_local_test = Y_train.iloc[valid_idx].values.ravel()\n",
    "\n",
    "    roc_auc, model = fit_predict_balanced_model(\n",
    "        X_local_train, y_local_train, X_local_test, y_local_test)\n",
    "    models.append(model)\n",
    "    cv_results_balanced.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Difference in terms of ROC-AUC using a random under-sampling')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = (pd.DataFrame({'Imbalanced model': cv_results_balanced}).unstack().reset_index())\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(y='level_0', x=0, data=df_results, whis=10.0)\n",
    "sns.despine(top=True, right=True, left=True)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(\n",
    "    plt.FuncFormatter(lambda x, pos: \"%i%%\" % (100 * x)))\n",
    "plt.xlabel('ROC-AUC')\n",
    "plt.ylabel('')\n",
    "plt.title('Difference in terms of ROC-AUC using a random under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_csv(prediction, filename):\n",
    "    sub = pd.read_csv('../submission.csv')\n",
    "    new = {'PerStatus':prediction}\n",
    "    sub.update(new)\n",
    "    sub.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7034581 , 0.11605781, 0.9212927 , ..., 0.9388906 , 0.03457132,\n",
       "       0.51414776], dtype=float32)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = models[0].predict(test)\n",
    "results = results[:, 0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if results[i] > thresh:\n",
    "        results[i] = 1\n",
    "    else:\n",
    "        results[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719.0"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_csv(results, 'balanced_dnn3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 50)                2350      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('dnn_selected.h5', monitor='val_accuracy', verbose=1, save_best_only=True, \n",
    "                            save_weights_only=False, mode='auto', save_freq=1)\n",
    "\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=100, verbose=1, mode='auto')\n",
    "\n",
    "LR_adj=ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4730 - recall: 0.7705 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 2/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4717 - recall: 0.7698 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 3/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4741 - recall: 0.7813 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 4/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4721 - recall: 0.7745 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 5/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4726 - recall: 0.7712 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 6/400\n",
      "721/727 [============================>.] - ETA: 0s - loss: 4.4719e-08 - accuracy: 0.4711 - recall: 0.7713\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4711 - recall: 0.7710 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 7/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4747 - recall: 0.7698 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 8/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4755 - recall: 0.7764 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 9/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4696 - recall: 0.7676 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 10/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4731 - recall: 0.7742 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 11/400\n",
      "721/727 [============================>.] - ETA: 0s - loss: 4.4768e-08 - accuracy: 0.4740 - recall: 0.7782\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4742 - recall: 0.7779 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 12/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4718 - recall: 0.7742 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 13/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4750 - recall: 0.7727 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 14/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7710 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 15/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4726 - recall: 0.7693 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 16/400\n",
      "715/727 [============================>.] - ETA: 0s - loss: 4.4877e-08 - accuracy: 0.4765 - recall: 0.7768\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4763 - recall: 0.7763 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 17/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4686 - recall: 0.7647 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 18/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4712 - recall: 0.7729 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 19/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4751 - recall: 0.7721 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 20/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4721 - recall: 0.7720 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 21/400\n",
      "721/727 [============================>.] - ETA: 0s - loss: 4.4757e-08 - accuracy: 0.4734 - recall: 0.7739\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4735 - recall: 0.7732 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 22/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4700 - recall: 0.7704 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 23/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4729 - recall: 0.7691 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 24/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4711 - recall: 0.7705 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 25/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4741 - recall: 0.7765 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 26/400\n",
      "720/727 [============================>.] - ETA: 0s - loss: 4.4803e-08 - accuracy: 0.4739 - recall: 0.7717\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4737 - recall: 0.7713 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 27/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4762 - recall: 0.7758 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 28/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4759 - recall: 0.7693 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 29/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4697 - recall: 0.7716 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 30/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4707 - recall: 0.7724 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 31/400\n",
      "709/727 [============================>.] - ETA: 0s - loss: 4.4825e-08 - accuracy: 0.4706 - recall: 0.7632\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4705 - recall: 0.7638 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 32/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4676 - recall: 0.7714 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 33/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4695 - recall: 0.7715 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 34/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7736 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 35/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4768 - recall: 0.7820 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 36/400\n",
      "692/727 [===========================>..] - ETA: 0s - loss: 4.4830e-08 - accuracy: 0.4727 - recall: 0.7761\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4715 - recall: 0.7745 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 37/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4744 - recall: 0.7765 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 38/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4693 - recall: 0.7688 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 39/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4702 - recall: 0.7699 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 40/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4761 - recall: 0.7758 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 41/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4703 - recall: 0.7681 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 42/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4729 - recall: 0.7741 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 43/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4723 - recall: 0.7758 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 44/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4740 - recall: 0.7746 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 45/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4753 - recall: 0.7693 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 46/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4743 - recall: 0.7790 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 47/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4707 - recall: 0.7688 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 48/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4751 - recall: 0.7801 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 49/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4750 - recall: 0.7749 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 50/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4803 - recall: 0.7699 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 51/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4733 - recall: 0.7710 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 52/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4797 - recall: 0.7767 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 53/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4754 - recall: 0.7730 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 54/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4699 - recall: 0.7659 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 55/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4732 - recall: 0.7664 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 56/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4748 - recall: 0.7756 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 57/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4704 - recall: 0.7729 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 58/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4732 - recall: 0.7704 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 59/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7705 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 60/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4761 - recall: 0.7732 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 61/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4762 - recall: 0.7787 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 62/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4717 - recall: 0.7732 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 63/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4742 - recall: 0.7760 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 64/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4801 - recall: 0.7842 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 65/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4715 - recall: 0.7749 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 66/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4761 - recall: 0.7702 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 67/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4717 - recall: 0.7703 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 68/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4694 - recall: 0.7679 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 69/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4691 - recall: 0.7707 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 70/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4721 - recall: 0.7688 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 71/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4757 - recall: 0.7775 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 72/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7757 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 73/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4724 - recall: 0.7741 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 74/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7791 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 75/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4766 - recall: 0.7751 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 76/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4685 - recall: 0.7735 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 77/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4679 - recall: 0.7635 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 78/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4791 - recall: 0.7795 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 79/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4755 - recall: 0.7731 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 80/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4704 - recall: 0.7709 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 81/400\n",
      "727/727 [==============================] - 2s 3ms/step - loss: 4.4811e-08 - accuracy: 0.4733 - recall: 0.7731 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 82/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4705 - recall: 0.7664 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 83/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7701 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 84/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4679 - recall: 0.7680 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 85/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4708 - recall: 0.7735 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 86/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7680 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 87/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4692 - recall: 0.7626 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 88/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4739 - recall: 0.7765 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 89/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4713 - recall: 0.7692 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 90/400\n",
      "727/727 [==============================] - 2s 3ms/step - loss: 4.4811e-08 - accuracy: 0.4738 - recall: 0.7760 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 91/400\n",
      "727/727 [==============================] - 2s 3ms/step - loss: 4.4811e-08 - accuracy: 0.4712 - recall: 0.7696 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 92/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7708 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 93/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4754 - recall: 0.7719 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 94/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4739 - recall: 0.7727 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 95/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4686 - recall: 0.7724 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 96/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4743 - recall: 0.7806 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 97/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4735 - recall: 0.7714 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 98/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4745 - recall: 0.7742 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 99/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4696 - recall: 0.7726 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 100/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4724 - recall: 0.7709 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 101/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4752 - recall: 0.7784 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 00101: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                    validation_split=0.2, callbacks=[early, LR_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.ylabel('train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'],loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history, 'accuracy', 'val_accuracy')\n",
    "show_train_history(history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocessing.scale(test)\n",
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = result.mean()\n",
    "\n",
    "for i in range(len(result)):\n",
    "    if result[i] > thresh:\n",
    "        result[i] = 1\n",
    "    else:\n",
    "        result[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_csv(result[:, 0].astype(int), 'ada_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
