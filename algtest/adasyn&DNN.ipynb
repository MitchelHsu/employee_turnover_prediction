{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import make_pipeline as imb_pipline\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, r2_score\n",
    "from sklearn import svm, tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../p_train.csv')\n",
    "target = pd.read_csv('../PerStatus.csv')\n",
    "data.drop(['Work Overtime'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../E_data/stest.csv')\n",
    "test.drop(['Unnamed: 0', 'PerStatus', 'PerNo', 'Work Overtime'], axis=1, inplace=True)\n",
    "test.columns = data.columns\n",
    "test.ffill(inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = data.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "categorical_columns = full.columns\n",
    "categorical_pipeline = make_pipeline(\n",
    "    SimpleImputer(missing_values=-1, strategy='most_frequent'),\n",
    "    OneHotEncoder(categories='auto'))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [('categorical_preprocessing', categorical_pipeline, categorical_columns)],\n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "def build_model(n_features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(n_features,),\n",
    "              kernel_initializer='glorot_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, kernel_initializer='glorot_normal', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', Recall(name='recall')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.keras import BalancedBatchGenerator\n",
    "\n",
    "def fit_predict_balanced_model(X_train, Y_train, X_test, Y_test):\n",
    "    model = build_model(X_train.shape[1])\n",
    "    training_generator = BalancedBatchGenerator(X_train, Y_train,\n",
    "                                                batch_size=100,\n",
    "                                                random_state=42)\n",
    "    model.fit_generator(generator=training_generator, epochs=50, verbose=1)\n",
    "    y_pred = model.predict_proba(X_test, batch_size=300)\n",
    "    return roc_auc_score(Y_test, y_pred), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8257 - accuracy: 0.5160 - recall: 0.7924\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7445 - accuracy: 0.5500 - recall: 0.7884\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5770 - recall: 0.7964\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6080 - recall: 0.7884\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6440 - recall: 0.7964\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6440 - recall: 0.7705\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6690 - recall: 0.7904\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7000 - recall: 0.7864\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7280 - recall: 0.7864\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7240 - recall: 0.7505\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7070 - recall: 0.7465\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7510 - recall: 0.7844\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7710 - recall: 0.7984\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7840 - recall: 0.8064\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7740 - recall: 0.7904\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7990 - recall: 0.7984\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8100 - recall: 0.8164\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8020 - recall: 0.8124\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8160 - recall: 0.8283\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8360 - recall: 0.8184\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8220 - recall: 0.8224\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8510 - recall: 0.8483\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8540 - recall: 0.8523\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8610 - recall: 0.8583\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8740 - recall: 0.8643\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8720 - recall: 0.8703\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8840 - recall: 0.8782\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8880 - recall: 0.8882\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.9030 - recall: 0.8942\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9100 - recall: 0.9242\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.9040 - recall: 0.9062\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9290 - recall: 0.9281\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9200 - recall: 0.9162\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9290 - recall: 0.9222\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.9290 - recall: 0.9222\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9250 - recall: 0.9182\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9400 - recall: 0.9301\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9430 - recall: 0.9501\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1991 - accuracy: 0.9500 - recall: 0.9501\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9500 - recall: 0.9481\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9520 - recall: 0.9521\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9500 - recall: 0.9521\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9550 - recall: 0.9581\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9470 - recall: 0.9421\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9640 - recall: 0.9661\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9610 - recall: 0.9641\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9710 - recall: 0.9661\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9650 - recall: 0.9621\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9780 - recall: 0.9780\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9600 - recall: 0.9561\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.5010 - recall: 0.1737\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7798 - accuracy: 0.5580 - recall: 0.2635\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.5830 - recall: 0.3214\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.6100 - recall: 0.3832\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6360 - recall: 0.4491\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6520 - recall: 0.4830\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6680 - recall: 0.5269\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.6980 - recall: 0.5629\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7220 - recall: 0.6028\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7410 - recall: 0.6687\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7280 - recall: 0.6427\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7510 - recall: 0.6886\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7530 - recall: 0.6846\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7900 - recall: 0.7485\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7810 - recall: 0.7206\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8130 - recall: 0.7844\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8040 - recall: 0.7844\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8260 - recall: 0.8164\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8340 - recall: 0.8084\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8310 - recall: 0.8144\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8440 - recall: 0.8383\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8710 - recall: 0.8683\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8640 - recall: 0.8683\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8740 - recall: 0.8623\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8730 - recall: 0.8743\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8850 - recall: 0.8922\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8860 - recall: 0.8743\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.9030 - recall: 0.9022\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.9030 - recall: 0.9022\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8950 - recall: 0.9082\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9040 - recall: 0.9062\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.9090 - recall: 0.9182\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2647 - accuracy: 0.9180 - recall: 0.9202\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.9180 - recall: 0.9261\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9450 - recall: 0.9481\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9350 - recall: 0.9222\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9270 - recall: 0.9321\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9290 - recall: 0.9301\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9580 - recall: 0.9521\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9510 - recall: 0.9581\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9610 - recall: 0.9681\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9460 - recall: 0.9421\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9520 - recall: 0.9561\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9570 - recall: 0.9681\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9630 - recall: 0.9621\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9670 - recall: 0.9721\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9510 - recall: 0.9521\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9660 - recall: 0.9601\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9710 - recall: 0.9780\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9770 - recall: 0.9800\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8170 - accuracy: 0.4900 - recall: 0.8509\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.5480 - recall: 0.8628\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.5630 - recall: 0.8529\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6020 - recall: 0.8429\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6360 - recall: 0.8370\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6490 - recall: 0.8211\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6650 - recall: 0.8231\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.6960 - recall: 0.8171\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7060 - recall: 0.7972\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7130 - recall: 0.7932\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7230 - recall: 0.7753\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7530 - recall: 0.8072\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7780 - recall: 0.8270\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7820 - recall: 0.8171\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7750 - recall: 0.7972\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.8070 - recall: 0.8270\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8100 - recall: 0.8111\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8320 - recall: 0.8390\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8470 - recall: 0.8469\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8360 - recall: 0.8370\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8320 - recall: 0.8231\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8600 - recall: 0.8529\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8640 - recall: 0.8410\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8770 - recall: 0.8807\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8780 - recall: 0.8628\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8900 - recall: 0.8668\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3173 - accuracy: 0.8910 - recall: 0.8887\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8930 - recall: 0.8887\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.9050 - recall: 0.8827\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9060 - recall: 0.8946\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.9100 - recall: 0.8986\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.9280 - recall: 0.9145\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9260 - recall: 0.9125\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9250 - recall: 0.9066\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9190 - recall: 0.8986\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9300 - recall: 0.9165\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.9500 - recall: 0.9483\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9300 - recall: 0.9264\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9470 - recall: 0.9483\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9570 - recall: 0.9463\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9560 - recall: 0.9523\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9530 - recall: 0.9384\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9630 - recall: 0.9662\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9610 - recall: 0.9463\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9620 - recall: 0.9523\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9630 - recall: 0.9523\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9660 - recall: 0.9682\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9600 - recall: 0.9543\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9740 - recall: 0.9682\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9710 - recall: 0.9662\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8671 - accuracy: 0.5030 - recall: 0.3221\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7511 - accuracy: 0.5780 - recall: 0.4115\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7230 - accuracy: 0.5840 - recall: 0.4394\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6310 - recall: 0.4990\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6380 - recall: 0.5229\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.6770 - recall: 0.5825\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6900 - recall: 0.6223\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6910 - recall: 0.6243\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7240 - recall: 0.7018\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7470 - recall: 0.6899\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7410 - recall: 0.7018\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7640 - recall: 0.7376\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7790 - recall: 0.7555\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8010 - recall: 0.7614\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8090 - recall: 0.7952\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7960 - recall: 0.7932\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8110 - recall: 0.7932\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8180 - recall: 0.8012\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8130 - recall: 0.8111\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8310 - recall: 0.8390\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8490 - recall: 0.8549\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8340 - recall: 0.8250\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8620 - recall: 0.8628\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8590 - recall: 0.8509\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8630 - recall: 0.8489\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8640 - recall: 0.8668\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8710 - recall: 0.8569\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8760 - recall: 0.8688\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8830 - recall: 0.8847\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9020 - recall: 0.9165\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8950 - recall: 0.8867\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9140 - recall: 0.9105\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.9030 - recall: 0.9145\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9110 - recall: 0.9304\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.9110 - recall: 0.9264\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9170 - recall: 0.9125\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9290 - recall: 0.9384\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9260 - recall: 0.9304\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9130 - recall: 0.9085\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9400 - recall: 0.9423\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9280 - recall: 0.9225\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9350 - recall: 0.9344\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9380 - recall: 0.9364\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9400 - recall: 0.9384\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9430 - recall: 0.9384\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9540 - recall: 0.9583\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9530 - recall: 0.9602\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9600 - recall: 0.9622\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9630 - recall: 0.9622\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9480 - recall: 0.9543\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7827 - accuracy: 0.5280 - recall: 0.8024\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7091 - accuracy: 0.5750 - recall: 0.8323\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5820 - recall: 0.7804\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6260 - recall: 0.7745\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6530 - recall: 0.7984\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.6610 - recall: 0.7685\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6880 - recall: 0.7764\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7160 - recall: 0.7605\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7350 - recall: 0.7485\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7390 - recall: 0.7525\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7450 - recall: 0.7505\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7820 - recall: 0.7864\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7710 - recall: 0.7824\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8050 - recall: 0.7824\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8060 - recall: 0.7904\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8250 - recall: 0.8124\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8290 - recall: 0.8184\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8430 - recall: 0.8144\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8380 - recall: 0.8224\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8670 - recall: 0.8623\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8520 - recall: 0.8283\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8760 - recall: 0.8623\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8650 - recall: 0.8723\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8840 - recall: 0.8583\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8880 - recall: 0.8762\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8980 - recall: 0.8643\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9010 - recall: 0.8962\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.9060 - recall: 0.8982\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.9130 - recall: 0.9022\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.9230 - recall: 0.9102\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9310 - recall: 0.9182\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9240 - recall: 0.9182\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9370 - recall: 0.9301\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2174 - accuracy: 0.9360 - recall: 0.9301\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9300 - recall: 0.9401\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9430 - recall: 0.9281\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9430 - recall: 0.9281\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9330 - recall: 0.9242\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9470 - recall: 0.9341\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9460 - recall: 0.9541\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9590 - recall: 0.9601\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9520 - recall: 0.9401\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9610 - recall: 0.9641\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9590 - recall: 0.9621\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9660 - recall: 0.9661\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9720 - recall: 0.9681\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9780 - recall: 0.9800\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9650 - recall: 0.9581\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9710 - recall: 0.9721\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9740 - recall: 0.9681\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.5120 - recall: 0.5449\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5730 - recall: 0.5868\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6110 - recall: 0.6447\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6500 - recall: 0.6906\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6590 - recall: 0.6906\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7020 - recall: 0.7385\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.6900 - recall: 0.7246\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7090 - recall: 0.7246\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7060 - recall: 0.7345\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7280 - recall: 0.7505\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7350 - recall: 0.7625\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7620 - recall: 0.7745\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7700 - recall: 0.7944\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7980 - recall: 0.7984\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7830 - recall: 0.8044\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7930 - recall: 0.8104\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8040 - recall: 0.8204\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8020 - recall: 0.8044\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8270 - recall: 0.8483\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8330 - recall: 0.8343\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8340 - recall: 0.8303\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8370 - recall: 0.8543\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8680 - recall: 0.8842\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8800 - recall: 0.9002\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8880 - recall: 0.9102\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8890 - recall: 0.8882\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.9020 - recall: 0.8982\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8990 - recall: 0.9002\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9070 - recall: 0.9082\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.9120 - recall: 0.9301\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.9180 - recall: 0.9261\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9170 - recall: 0.9301\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9140 - recall: 0.9202\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9290 - recall: 0.9281\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9370 - recall: 0.9481\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9350 - recall: 0.9381\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9370 - recall: 0.9341\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9490 - recall: 0.9501\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9570 - recall: 0.9561\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9560 - recall: 0.9621\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9550 - recall: 0.9501\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9630 - recall: 0.9621\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9600 - recall: 0.9661\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9480 - recall: 0.9441\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9650 - recall: 0.9661\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9650 - recall: 0.9641\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9680 - recall: 0.9681\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9670 - recall: 0.9701\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9740 - recall: 0.9760\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9760 - recall: 0.9780\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8332 - accuracy: 0.5020 - recall: 0.6966\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7389 - accuracy: 0.5350 - recall: 0.7086\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6130 - recall: 0.8024\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6450 - recall: 0.7705\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6380 - recall: 0.7525\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6760 - recall: 0.7645\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6910 - recall: 0.7764\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7130 - recall: 0.7804\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7440 - recall: 0.7924\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7300 - recall: 0.7665\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7470 - recall: 0.7725\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7490 - recall: 0.7725\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7600 - recall: 0.7784\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7610 - recall: 0.7685\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7930 - recall: 0.8164\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8370 - recall: 0.8343\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8120 - recall: 0.8244\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8240 - recall: 0.8383\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8420 - recall: 0.8263\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8400 - recall: 0.8363\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8480 - recall: 0.8483\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8700 - recall: 0.8802\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8520 - recall: 0.8403\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8710 - recall: 0.8683\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8830 - recall: 0.8703\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8860 - recall: 0.8822\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8970 - recall: 0.8962\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8950 - recall: 0.8902\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9190 - recall: 0.9142\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9210 - recall: 0.9202\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2559 - accuracy: 0.9150 - recall: 0.9082\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9050 - recall: 0.9022\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.9130 - recall: 0.9062\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9170 - recall: 0.9082\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9240 - recall: 0.9102\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9270 - recall: 0.9162\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9310 - recall: 0.9341\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9440 - recall: 0.9521\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9290 - recall: 0.9242\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9540 - recall: 0.9481\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9520 - recall: 0.9481\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9490 - recall: 0.9421\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9710 - recall: 0.9721\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9630 - recall: 0.9641\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9600 - recall: 0.9641\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9570 - recall: 0.9501\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9620 - recall: 0.9641\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9660 - recall: 0.9581\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9680 - recall: 0.9661\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9750 - recall: 0.9800\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8389 - accuracy: 0.4750 - recall: 0.1776\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.5610 - recall: 0.2914\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5820 - recall: 0.3353\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6170 - recall: 0.3992\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6420 - recall: 0.4611\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6550 - recall: 0.5250\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6760 - recall: 0.5329\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.6950 - recall: 0.5749\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7110 - recall: 0.6128\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7220 - recall: 0.6487\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7620 - recall: 0.6886\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7850 - recall: 0.7285\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7700 - recall: 0.7086\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7900 - recall: 0.7625\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7760 - recall: 0.7345\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7940 - recall: 0.7924\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8280 - recall: 0.8064\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8390 - recall: 0.8124\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8390 - recall: 0.8383\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8240 - recall: 0.8024\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8480 - recall: 0.8343\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8400 - recall: 0.8263\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8750 - recall: 0.8782\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8730 - recall: 0.8603\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8710 - recall: 0.8603\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8930 - recall: 0.8882\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8820 - recall: 0.8822\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.9060 - recall: 0.9062\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9180 - recall: 0.9142\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.9080 - recall: 0.9122\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2680 - accuracy: 0.9030 - recall: 0.9162\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9110 - recall: 0.9162\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9260 - recall: 0.9222\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9280 - recall: 0.9202\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9310 - recall: 0.9401\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9340 - recall: 0.9401\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9470 - recall: 0.9541\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9540 - recall: 0.9661\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9490 - recall: 0.9541\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9500 - recall: 0.9541\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9490 - recall: 0.9461\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9530 - recall: 0.9521\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9560 - recall: 0.9521\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9480 - recall: 0.9401\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9580 - recall: 0.9581\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9610 - recall: 0.9741\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9700 - recall: 0.9741\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9730 - recall: 0.9760\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9630 - recall: 0.9561\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9750 - recall: 0.9800\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7838 - accuracy: 0.5050 - recall: 0.5609\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5820 - recall: 0.6407\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6040 - recall: 0.6447\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6250 - recall: 0.6567\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6370 - recall: 0.6367\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6600 - recall: 0.6487\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6720 - recall: 0.6607\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7260 - recall: 0.6986\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7330 - recall: 0.7285\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7250 - recall: 0.6946\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7280 - recall: 0.7166\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7480 - recall: 0.7166\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7620 - recall: 0.7485\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7860 - recall: 0.7565\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8000 - recall: 0.7605\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7960 - recall: 0.7545\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8000 - recall: 0.7545\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8130 - recall: 0.7844\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8290 - recall: 0.8084\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8320 - recall: 0.8224\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3685 - accuracy: 0.8430 - recall: 0.8343\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8600 - recall: 0.8443\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8670 - recall: 0.8463\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8550 - recall: 0.8343\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8790 - recall: 0.8383\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3223 - accuracy: 0.8790 - recall: 0.8583\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8920 - recall: 0.8762\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.9030 - recall: 0.8962\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8900 - recall: 0.8563\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.9080 - recall: 0.8862\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.8900 - recall: 0.8802\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9120 - recall: 0.8942\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9080 - recall: 0.8882\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.9010 - recall: 0.8902\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9210 - recall: 0.9062\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9240 - recall: 0.8962\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9380 - recall: 0.9202\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9340 - recall: 0.9142\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9460 - recall: 0.9202\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9470 - recall: 0.9601\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.9360 - recall: 0.9102\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9550 - recall: 0.9481\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9520 - recall: 0.9341\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9470 - recall: 0.9401\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9560 - recall: 0.9501\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9580 - recall: 0.9541\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9680 - recall: 0.9661\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9510 - recall: 0.9381\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9710 - recall: 0.9661\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9650 - recall: 0.9621\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7584 - accuracy: 0.5370 - recall: 0.4770\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.5840 - recall: 0.5070\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6260 - recall: 0.5768\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.6540 - recall: 0.6108\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6710 - recall: 0.6367\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6820 - recall: 0.6208\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7090 - recall: 0.6707\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7320 - recall: 0.7126\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7300 - recall: 0.7026\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7610 - recall: 0.7365\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7590 - recall: 0.7385\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7860 - recall: 0.7545\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7810 - recall: 0.7745\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7850 - recall: 0.7944\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7880 - recall: 0.7705\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8180 - recall: 0.8024\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8060 - recall: 0.7824\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8280 - recall: 0.8144\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8400 - recall: 0.8343\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8510 - recall: 0.8423\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8520 - recall: 0.8483\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8720 - recall: 0.8643\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8750 - recall: 0.8523\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8900 - recall: 0.8683\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9010 - recall: 0.8822\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9040 - recall: 0.9002\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9010 - recall: 0.8942\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.8890 - recall: 0.8822\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9060 - recall: 0.9122\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9200 - recall: 0.9082\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9240 - recall: 0.9222\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9330 - recall: 0.9242\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9210 - recall: 0.9202\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9370 - recall: 0.9202\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9350 - recall: 0.9321\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9350 - recall: 0.9361\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9450 - recall: 0.9381\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9460 - recall: 0.9381\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9560 - recall: 0.9661\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9650 - recall: 0.9561\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9540 - recall: 0.9481\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9590 - recall: 0.9581\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9630 - recall: 0.9681\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9590 - recall: 0.9561\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9670 - recall: 0.9661\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9690 - recall: 0.9701\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9660 - recall: 0.9661\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9740 - recall: 0.9721\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9740 - recall: 0.9741\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9760 - recall: 0.9701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "full = preprocessor.fit_transform(full)\n",
    "models = []\n",
    "\n",
    "cv_results_balanced = []\n",
    "for train_idx, valid_idx in skf.split(X_train, Y_train):\n",
    "    X_local_train = preprocessor.transform(X_train.iloc[train_idx])\n",
    "    y_local_train = Y_train.iloc[train_idx].values.ravel()\n",
    "    X_local_test = preprocessor.transform(X_train.iloc[valid_idx])\n",
    "    y_local_test = Y_train.iloc[valid_idx].values.ravel()\n",
    "\n",
    "    roc_auc, model = fit_predict_balanced_model(\n",
    "        X_local_train, y_local_train, X_local_test, y_local_test)\n",
    "    models.append(model)\n",
    "    cv_results_balanced.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Difference in terms of ROC-AUC using a random under-sampling')"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_results = (pd.DataFrame({'Imbalanced model': cv_results_balanced}).unstack().reset_index())\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(y='level_0', x=0, data=df_results, whis=10.0)\n",
    "sns.despine(top=True, right=True, left=True)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(\n",
    "    plt.FuncFormatter(lambda x, pos: \"%i%%\" % (100 * x)))\n",
    "plt.xlabel('ROC-AUC')\n",
    "plt.ylabel('')\n",
    "plt.title('Difference in terms of ROC-AUC using a random under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_csv(prediction, filename):\n",
    "    sub = pd.read_csv('../submission.csv')\n",
    "    new = {'PerStatus':prediction}\n",
    "    sub.update(new)\n",
    "    sub.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7034581 , 0.11605781, 0.9212927 , ..., 0.9388906 , 0.03457132,\n",
       "       0.51414776], dtype=float32)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = models[0].predict(test)\n",
    "results = results[:, 0]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.8\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if results[i] > thresh:\n",
    "        results[i] = 1\n",
    "    else:\n",
    "        results[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719.0"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_csv(results, 'balanced_dnn3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 50)                2350      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('dnn_selected.h5', monitor='val_accuracy', verbose=1, save_best_only=True, \n",
    "                            save_weights_only=False, mode='auto', save_freq=1)\n",
    "\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=100, verbose=1, mode='auto')\n",
    "\n",
    "LR_adj=ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4730 - recall: 0.7705 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 2/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4717 - recall: 0.7698 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 3/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4741 - recall: 0.7813 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 4/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4721 - recall: 0.7745 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 5/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4726 - recall: 0.7712 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 6/400\n",
      "721/727 [============================>.] - ETA: 0s - loss: 4.4719e-08 - accuracy: 0.4711 - recall: 0.7713\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4711 - recall: 0.7710 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 7/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4747 - recall: 0.7698 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 8/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4755 - recall: 0.7764 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 9/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4696 - recall: 0.7676 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 10/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4731 - recall: 0.7742 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 11/400\n",
      "721/727 [============================>.] - ETA: 0s - loss: 4.4768e-08 - accuracy: 0.4740 - recall: 0.7782\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4742 - recall: 0.7779 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 12/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4718 - recall: 0.7742 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 13/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4750 - recall: 0.7727 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 14/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7710 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 15/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4726 - recall: 0.7693 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 16/400\n",
      "715/727 [============================>.] - ETA: 0s - loss: 4.4877e-08 - accuracy: 0.4765 - recall: 0.7768\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4763 - recall: 0.7763 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 17/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4686 - recall: 0.7647 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 18/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4712 - recall: 0.7729 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 19/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4751 - recall: 0.7721 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 20/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4721 - recall: 0.7720 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 21/400\n",
      "721/727 [============================>.] - ETA: 0s - loss: 4.4757e-08 - accuracy: 0.4734 - recall: 0.7739\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4735 - recall: 0.7732 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 22/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4700 - recall: 0.7704 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 23/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4729 - recall: 0.7691 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 24/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4711 - recall: 0.7705 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 25/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4741 - recall: 0.7765 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 26/400\n",
      "720/727 [============================>.] - ETA: 0s - loss: 4.4803e-08 - accuracy: 0.4739 - recall: 0.7717\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4737 - recall: 0.7713 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 27/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4762 - recall: 0.7758 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 28/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4759 - recall: 0.7693 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 29/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4697 - recall: 0.7716 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 30/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4707 - recall: 0.7724 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 31/400\n",
      "709/727 [============================>.] - ETA: 0s - loss: 4.4825e-08 - accuracy: 0.4706 - recall: 0.7632\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4705 - recall: 0.7638 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 32/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4676 - recall: 0.7714 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 33/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4695 - recall: 0.7715 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 34/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7736 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 35/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4768 - recall: 0.7820 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 36/400\n",
      "692/727 [===========================>..] - ETA: 0s - loss: 4.4830e-08 - accuracy: 0.4727 - recall: 0.7761\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4715 - recall: 0.7745 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 37/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4744 - recall: 0.7765 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 38/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4693 - recall: 0.7688 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 39/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4702 - recall: 0.7699 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 40/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4761 - recall: 0.7758 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 41/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4703 - recall: 0.7681 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 42/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4729 - recall: 0.7741 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 43/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4723 - recall: 0.7758 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 44/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4740 - recall: 0.7746 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 45/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4753 - recall: 0.7693 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 46/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4743 - recall: 0.7790 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 47/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4707 - recall: 0.7688 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 48/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4751 - recall: 0.7801 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 49/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4750 - recall: 0.7749 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 50/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4803 - recall: 0.7699 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 51/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4733 - recall: 0.7710 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 52/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4797 - recall: 0.7767 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 53/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4754 - recall: 0.7730 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 54/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4699 - recall: 0.7659 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 55/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4732 - recall: 0.7664 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 56/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4748 - recall: 0.7756 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 57/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4704 - recall: 0.7729 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 58/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4732 - recall: 0.7704 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 59/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7705 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 60/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4761 - recall: 0.7732 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 61/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4762 - recall: 0.7787 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 62/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4717 - recall: 0.7732 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 63/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4742 - recall: 0.7760 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 64/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4801 - recall: 0.7842 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 65/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4715 - recall: 0.7749 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 66/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4761 - recall: 0.7702 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 67/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4717 - recall: 0.7703 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 68/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4694 - recall: 0.7679 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 69/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4691 - recall: 0.7707 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 70/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4721 - recall: 0.7688 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 71/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4757 - recall: 0.7775 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 72/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7757 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 73/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4724 - recall: 0.7741 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 74/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7791 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 75/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4766 - recall: 0.7751 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 76/400\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 4.4811e-08 - accuracy: 0.4685 - recall: 0.7735 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 77/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4679 - recall: 0.7635 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 78/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4791 - recall: 0.7795 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 79/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4755 - recall: 0.7731 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 80/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4704 - recall: 0.7709 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 81/400\n",
      "727/727 [==============================] - 2s 3ms/step - loss: 4.4811e-08 - accuracy: 0.4733 - recall: 0.7731 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 82/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4705 - recall: 0.7664 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 83/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7701 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 84/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4679 - recall: 0.7680 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 85/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4708 - recall: 0.7735 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 86/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4746 - recall: 0.7680 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 87/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4692 - recall: 0.7626 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 88/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4739 - recall: 0.7765 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 89/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4713 - recall: 0.7692 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 90/400\n",
      "727/727 [==============================] - 2s 3ms/step - loss: 4.4811e-08 - accuracy: 0.4738 - recall: 0.7760 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 91/400\n",
      "727/727 [==============================] - 2s 3ms/step - loss: 4.4811e-08 - accuracy: 0.4712 - recall: 0.7696 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 92/400\n",
      "727/727 [==============================] - 2s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4734 - recall: 0.7708 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 93/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4754 - recall: 0.7719 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 94/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4739 - recall: 0.7727 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 95/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4686 - recall: 0.7724 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 96/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4743 - recall: 0.7806 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 97/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4735 - recall: 0.7714 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 98/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4745 - recall: 0.7742 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 99/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4696 - recall: 0.7726 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 100/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4724 - recall: 0.7709 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 101/400\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 4.4811e-08 - accuracy: 0.4752 - recall: 0.7784 - val_loss: 1.1921e-07 - val_accuracy: 0.8140 - val_recall: 0.8140\n",
      "Epoch 00101: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                    validation_split=0.2, callbacks=[early, LR_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.ylabel('train')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train','validation'],loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history, 'accuracy', 'val_accuracy')\n",
    "show_train_history(history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocessing.scale(test)\n",
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = result.mean()\n",
    "\n",
    "for i in range(len(result)):\n",
    "    if result[i] > thresh:\n",
    "        result[i] = 1\n",
    "    else:\n",
    "        result[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_csv(result[:, 0].astype(int), 'ada_DNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
